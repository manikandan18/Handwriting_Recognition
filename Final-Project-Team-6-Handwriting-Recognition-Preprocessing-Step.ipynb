{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import numpy as np\n",
    "\n",
    "train_image_list = []\n",
    "test_image_list = []\n",
    "y_train_list = []\n",
    "y_truth_list = []\n",
    "\n",
    "# The below method would crop the individual words with the whole png file and create a new image file (.png)\n",
    "# file for each word. pytesseract python library was used to do this activity. Please note, the task is to identify\n",
    "# whose handwriting the image belongs to rather than identifying correct word within the image.\n",
    "# The output .png file produced with each word would be like Mani_1.png, Mani_2.png etc. Here, label 'Mani' is used as\n",
    "# as output of prediction once the model gets fitted.\n",
    "\n",
    "def generate_text_images(image_path, j, image_name):\n",
    "  # Load the image\n",
    "  image = Image.open(image_path)\n",
    "\n",
    "  # Perform OCR and get data including bounding boxes\n",
    "  data = pytesseract.image_to_data(image, output_type=Output.DICT)  \n",
    "  # Create a drawing object\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  output_directory = '/Users/manikanr/Documents/AI-Items/Handwriting-task/word_images/'\n",
    "  os.makedirs(output_directory, exist_ok=True)\n",
    "  i=0  \n",
    "  # Process the data\n",
    "  for i in range(len(data['text'])):\n",
    "    # Extract word bounding boxes\n",
    "    word, x, y, w, h = data['text'][i], data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "\n",
    "    # Filter out non-word elements\n",
    "    if word.strip() != '' and int(data['conf'][i]) > 0:\n",
    "        # Optionally, print word and bounding box coordinates for reference\n",
    "        #print(f\"Word: {word}, Bounding Box: {(x, y, x + w, y + h)}\")\n",
    "        \n",
    "        # Crop and save the word as a separate image\n",
    "        word_image = image.crop((x, y, x + w, y + h))\n",
    "        word_image.save(f\"{output_directory}{image_name}_{j}.png\")\n",
    "        if (j<=300):\n",
    "          train_image = np.array(word_image)  \n",
    "          train_image_list.append(train_image)\n",
    "          y_train_list.append(image_name)  \n",
    "        else:\n",
    "          test_image = np.array(word_image) \n",
    "          test_image_list.append(test_image)\n",
    "          y_truth_list.append(image_name)  \n",
    "        j = j+1;\n",
    "  return j\n",
    "j=1\n",
    "for i in range(1,5):\n",
    "  image_path = \"/Users/manikanr/Documents/AI-Items/Handwriting-task/Handwritten_Mani_\"+str(i)+\".png\"  \n",
    "  j = generate_text_images(image_path, j, 'Mani')\n",
    "\n",
    "j = 1 \n",
    "for k in range(1,4): \n",
    "  image_path = \"/Users/manikanr/Documents/AI-Items/Handwriting-task/Handwritten_Priya_\"+str(k)+\".png\"  \n",
    "  j = generate_text_images(image_path, j, 'Priya')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
